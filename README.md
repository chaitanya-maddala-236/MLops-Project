# Wine Quality Prediction - MLOps Project

An end-to-end Machine Learning Operations (MLOps) pipeline for predicting wine quality using physicochemical properties. This project demonstrates industry best practices for building, training, evaluating, and deploying machine learning models with complete experiment tracking and a web interface for predictions.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Architecture](#project-architecture)
- [Dataset](#dataset)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Pipeline Components](#pipeline-components)
- [Configuration](#configuration)
- [Model Details](#model-details)
- [Web Application](#web-application)
- [Experiment Tracking](#experiment-tracking)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

This project implements a complete MLOps workflow for predicting wine quality based on physicochemical tests. The system uses an ElasticNet regression model to predict wine quality scores (0-10) based on 11 input features including acidity, sugar content, pH levels, and alcohol percentage.

**Key Highlights:**
- End-to-end automated ML pipeline from data ingestion to model deployment
- ElasticNet regression model with hyperparameter tuning (alpha=0.2, l1_ratio=0.1)
- MLflow and DagHub integration for comprehensive experiment tracking
- Flask web application for real-time predictions
- Modular, production-ready code architecture
- Complete data validation and transformation pipeline

## âœ¨ Features

- **Automated Data Pipeline**: Downloads and processes wine quality dataset from GitHub
- **Data Validation**: Schema validation ensuring data integrity with 12 features
- **Train-Test Split**: Automated 75-25 split for model training and evaluation
- **ElasticNet Model**: L1/L2 regularized regression for robust predictions
- **Experiment Tracking**: Full MLflow and DagHub integration with metrics logging (RMSE, MAE, RÂ²)
- **Model Registry**: Automated model versioning and registration in MLflow
- **Flask Web App**: User-friendly interface for real-time wine quality predictions
- **Configuration Management**: YAML-based configuration for easy hyperparameter tuning
- **Logging System**: Comprehensive logging for debugging and monitoring
- **Modular Architecture**: Separate components for each pipeline stage
- **Type Safety**: Type annotations with runtime validation using `ensure` library

## ğŸ—ï¸ Project Architecture

The project follows a modular architecture with five distinct pipeline stages:

```
Data Ingestion â†’ Data Validation â†’ Data Transformation â†’ Model Training â†’ Model Evaluation
```

**Pipeline Flow:**
1. **Data Ingestion**: Downloads wine quality dataset (ZIP format) and extracts it
2. **Data Validation**: Validates 12 columns against schema (11 features + 1 target)
3. **Data Transformation**: Performs train-test split (75-25)
4. **Model Training**: Trains ElasticNet model with configured hyperparameters
5. **Model Evaluation**: Evaluates model performance and logs to MLflow/DagHub

Each stage is independently configurable and can be executed separately or as part of the complete pipeline.

## ğŸ“Š Dataset

**Source**: Red Wine Quality Dataset  
**URL**: https://github.com/krishnaik06/datasets/raw/refs/heads/main/winequality-data.zip  
**Size**: 1,599 samples Ã— 12 features

**Input Features** (11):
- `fixed acidity`: Tartaric acid concentration (g/dmÂ³)
- `volatile acidity`: Acetic acid concentration (g/dmÂ³)
- `citric acid`: Citric acid concentration (g/dmÂ³)
- `residual sugar`: Remaining sugar after fermentation (g/dmÂ³)
- `chlorides`: Salt concentration (g/dmÂ³)
- `free sulfur dioxide`: Free SOâ‚‚ concentration (mg/dmÂ³)
- `total sulfur dioxide`: Total SOâ‚‚ concentration (mg/dmÂ³)
- `density`: Wine density (g/cmÂ³)
- `pH`: Acidity level (0-14 scale)
- `sulphates`: Potassium sulphate concentration (g/dmÂ³)
- `alcohol`: Alcohol percentage (% vol)

**Target Variable**: `quality` (score between 0-10)

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- Git

### Setup Instructions

1. **Clone the repository**
   ```bash
   git clone https://github.com/chaitanya-maddala-236/MLops-Project.git
   cd MLops-Project
   ```

2. **Create a virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up configuration files**
   - Update `config/config.yaml` with your project settings
   - Configure `config/schema.yaml` for data validation rules
   - Adjust hyperparameters in `config/params.yaml`

## ğŸ’» Usage

### Running the Complete Pipeline

Execute all pipeline stages sequentially:

```bash
python main.py
```

This will run all five stages:
1. Data Ingestion
2. Data Validation
3. Data Transformation
4. Model Training
5. Model Evaluation (with MLflow logging)

### Running the Web Application

Start the Flask web server for predictions:

```bash
python app.py
```

The application will be available at `http://localhost:8080`

**Available Endpoints:**
- `GET /` - Home page with input form
- `GET /train` - Trigger model training pipeline
- `POST /predict` - Submit wine features for quality prediction

### Running Individual Pipeline Stages

Execute specific stages independently:

```python
from src.datascience.pipeline.data_ingestion_pipeline import DataIngestionTrainingPipeline
from src.datascience.pipeline.data_validation_pipeline import DataValidationTrainingPipeline
from src.datascience.pipeline.data_transformation_pipeline import DataTransformationTrainingPipeline
from src.datascience.pipeline.model_trainer_pipeline import ModelTrainerTrainingPipeline
from src.datascience.pipeline.model_evaluation_pipeline import ModelEvaluationTrainingPipeline

# Example: Run only data ingestion
pipeline = DataIngestionTrainingPipeline()
pipeline.initiate_data_ingestion()
```

### Making Predictions Programmatically

```python
from src.datascience.pipeline.prediction_pipeline import PredictionPipeline
import numpy as np

# Create prediction pipeline
predictor = PredictionPipeline()

# Sample wine features [fixed_acidity, volatile_acidity, citric_acid, ...]
features = np.array([[7.4, 0.70, 0.00, 1.9, 0.076, 11.0, 34.0, 0.9978, 3.51, 0.56, 9.4]])

# Get prediction
quality_score = predictor.predict(features)
print(f"Predicted Wine Quality: {quality_score}")
```

## ğŸ“ Project Structure

```
MLops-Project/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/           # CI/CD workflows (placeholder)
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml          # Pipeline configuration (paths, URLs)
â”œâ”€â”€ src/
â”‚   â””â”€â”€ datascience/
â”‚       â”œâ”€â”€ __init__.py      # Logging configuration
â”‚       â”œâ”€â”€ components/      # Core pipeline components
â”‚       â”‚   â”œâ”€â”€ data_ingestion.py
â”‚       â”‚   â”œâ”€â”€ data_validation.py
â”‚       â”‚   â”œâ”€â”€ data_transformation.py
â”‚       â”‚   â”œâ”€â”€ model_trainer.py
â”‚       â”‚   â””â”€â”€ model_evaluation.py
â”‚       â”œâ”€â”€ config/
â”‚       â”‚   â””â”€â”€ configuration.py  # Configuration manager
â”‚       â”œâ”€â”€ constants/
â”‚       â”‚   â””â”€â”€ __init__.py  # File paths constants
â”‚       â”œâ”€â”€ entity/
â”‚       â”‚   â””â”€â”€ config_entity.py  # Data classes for configs
â”‚       â”œâ”€â”€ pipeline/        # Pipeline orchestration
â”‚       â”‚   â”œâ”€â”€ data_ingestion_pipeline.py
â”‚       â”‚   â”œâ”€â”€ data_validation_pipeline.py
â”‚       â”‚   â”œâ”€â”€ data_transformation_pipeline.py
â”‚       â”‚   â”œâ”€â”€ model_trainer_pipeline.py
â”‚       â”‚   â”œâ”€â”€ model_evaluation_pipeline.py
â”‚       â”‚   â””â”€â”€ prediction_pipeline.py
â”‚       â””â”€â”€ utils/
â”‚           â””â”€â”€ common.py    # Utility functions (YAML, JSON, logging)
â”œâ”€â”€ research/                # Jupyter notebooks for experimentation
â”‚   â”œâ”€â”€ 1_data_ingestion.ipynb
â”‚   â”œâ”€â”€ 2_data_validation.ipynb
â”‚   â”œâ”€â”€ 3_data_transformation.ipynb
â”‚   â”œâ”€â”€ 4_model_trainer.ipynb
â”‚   â””â”€â”€ 5_model_evaluation.ipynb
â”œâ”€â”€ templates/               # Flask HTML templates
â”‚   â”œâ”€â”€ index.html          # Input form
â”‚   â””â”€â”€ results.html        # Prediction results
â”œâ”€â”€ artifacts/               # Generated artifacts (data, models, metrics)
â”‚   â”œâ”€â”€ data_ingestion/
â”‚   â”œâ”€â”€ data_validation/
â”‚   â”œâ”€â”€ data_transformation/
â”‚   â”œâ”€â”€ model_trainer/
â”‚   â””â”€â”€ model_evaluation/
â”œâ”€â”€ logs/                    # Application logs
â”œâ”€â”€ app.py                   # Flask web application
â”œâ”€â”€ main.py                  # Main pipeline executor
â”œâ”€â”€ params.yaml              # Model hyperparameters
â”œâ”€â”€ schema.yaml              # Data schema definitions
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ template.py              # Project structure generator
â”œâ”€â”€ Dockerfile               # Docker configuration (placeholder)
â””â”€â”€ README.md                # Project documentation
```â”€â”€ data_validation.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â”œâ”€â”€ model_trainer.py
â”‚   â”‚   â””â”€â”€ model_evaluation.py
â”‚   â”œâ”€â”€ config/              # Configuration manager
â”‚   â”‚   â””â”€â”€ configuration.py
â”‚   â”œâ”€â”€ entity/              # Data entities and configs
â”‚   â”œâ”€â”€ pipeline/            # Pipeline stages
â”‚   â””â”€â”€ utils/               # Utility functions
â”œâ”€â”€ artifacts/               # Generated artifacts
â”œâ”€â”€ notebooks/               # Jupyter notebooks for exploration
â”œâ”€â”€ research/                # Experimental code
â”œâ”€â”€ main.py                  # Main pipeline executor
â”œâ”€â”€ requirements.txt         # Project dependencies
â””â”€â”€ README.md               # Project documentation
```

## ğŸ”§ Pipeline Components

### 1. Data Ingestion
- Fetches data from configured sources
- Handles data downloading and extraction
- Organizes raw data for processing

### 2. Data Validation
- Validates data against defined schema
- Checks data types and column names
- Generates validation status reports

### 3. Data Transformation
- Performs feature engineering
- Handles missing values and outliers
- Applies data preprocessing techniques
- Splits data into training and testing sets

### 4. Model Training
- Trains machine learning models with configured parameters
- Supports multiple algorithms
- Saves trained models for evaluation

### 5. Model Evaluation
- Evaluates model performance using various metrics
- Logs results to MLflow and DagHub
- Generates performance reports and visualizations

## âš™ï¸ Configuration

The project uses three main configuration files:

### config.yaml
Main configuration for pipeline components including:
- Data source locations
- Artifact directories
- Component-specific settings

### schema.yaml
Defines the expected data structure:
- Column names and types
- Target variable specifications
- Data validation rules

### params.yaml
Machine learning hyperparameters:
- Model-specific parameters
- Training configurations
- Evaluation metrics

## ğŸ“Š Model Tracking

This project integrates with **MLflow** and **DagHub** for comprehensive experiment tracking:

- **Experiment Logging**: All training runs are automatically logged
- **Metrics Tracking**: Performance metrics are recorded for each experiment
- **Model Registry**: Trained models are versioned and stored
- **Visualization**: Compare experiments and visualize model performance

### Setting up MLflow/DagHub

1. Create an account on [DagHub](https://dagshub.com/)
2. Set up your credentials
3. Update the tracking URI in your configuration
4. Run experiments and view results in the DagHub interface

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¤ Author

**Chaitanya Maddala**

- GitHub: [@chaitanya-maddala-236](https://github.com/chaitanya-maddala-236)

## ğŸ™ Acknowledgments

- MLflow for experiment tracking capabilities
- DagHub for model versioning and collaboration
- The open-source community for various tools and libraries used in this project

---

For questions or support, please open an issue in the GitHub repository.
